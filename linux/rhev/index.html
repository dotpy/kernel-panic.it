<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

<head>

  <meta http-equiv="content-type" content="text/html; charset=utf-8" />
  <meta name="resource-type" content="document" />
  <meta name="keywords" content="Linux,Redhat,Enterprise,Virtualization,RHEV,RHEL,API,Python,Deployment,Automation,Kickstart" />
  <meta name="distribution" content="global" />
  <meta name="author" content="Daniele Mazzocchio" />
  <meta name="copyright" content="This document copyright 2005-2011 by Kernel-Panic.it." />

  <title>Automatic Virtual Machine deployment using the RHEV API and Python</title>

  <link rel="stylesheet" type="text/css" href="../../css/docs.css" />
  <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />

</head>

<body>

  <div class="navigation">
    <ul>
      <li class="prev"><span class="nav-list" ><span>Previous</span></span></li>
      <li class="up"><a class="nav-list" href="../../linux.html"><span>Up</span></a></li>
      <li class="next"><span class="nav-list" ><span>Next</span></span></li>
      <li class="home"><a class="nav-list" href="../../index.html"><span>Home</span></a></li>
    </ul>
    <h3>Automatic Virtual Machine deployment using the RHEV API and Python</h3>
    <div>Up: <a href="../../linux.html">Linux</a>
    </div>
  </div>

  <hr />

<h1>Automatic Virtual Machine deployment using the RHEV API and Python</h1>
  <div id="subtitle">Author: <a href="mailto:danix@kernel-panic.it">Daniele Mazzocchio</a><br />
                     Last update: Sep 8, 2014
  </div>

<p>The purpose of this document is to give a quick overview of the Python <acronym title="RedHat Enterprise Virtualization">RHEV</acronym> <acronym title="Application Programming Interface">API</acronym>, by creating a basic script for deploying new <acronym title="RedHat Enterprise Linux">RHEL</acronym> virtual machines; such a script could be used for faster VM creation (by bypassing the web interface completely) or for automating the deployment process.</p>
<p>So let's talk prerequisites. The first choice is whether to create new virtual machines using templates or kickstart (i.e. network installation); though the most natural choice would be using templates, there are a number of reasons why I prefer the kickstart installation method:</p>

<ul>
  <li>newly installed machines are up to date and registered on the RedHat Network;</li>
  <li>post-installation scripts can be shared across physical and virtual machines, thus greatly simplifying standardization and maintenance;</li>
  <li>it's easier to keep a bunch of scripts up to date rather than one or more templates;</li>
  <li>installation scripts are much more flexible than templates.</li>
</ul>

<p>Though we'll be installing over the network, another thing on my wishlist was to avoid using <acronym title="Preboot Execution Environment">PXE</acronym>/<acronym title="Dynamic Host Configuration Protocol">DHCP</acronym> for network boot; besides the potential security and reliability issues with both PXE and DHCP, DHCP can increase the administrative overhead on segmented networks (where each network segment may require its own DHCP server, or a DHCP relay agent) or on multi-OS networks, not to mention the hassle of creating static DHCP reservations.</p>
<p>The great thing is that RHEV allows you to benefit from the advantages of PXE/DHCP, without any of the drawbacks, by passing kernel (<tt>vmlinuz</tt>), initial ramdisk image (<tt>initrd.img</tt>) and boot parameters directly to the virtual machine. The required files can be found in the <tt>/images/pxeboot</tt> directory of the install media (<tt>boot.iso</tt>), which can be downloaded from the RedHat website; files must be uploaded on the ISO domain, using the <tt>rhevm-iso-uploader(8)</tt> command:</p>

<div class="code">
<pre>
# <kbd>rhevm-iso-uploader --iso-domain=&lt;ISODomain&gt; upload initrd.img vmlinuz</kbd>
Please provide the REST API password for the admin@internal oVirt Engine user (CTRL+D to abort): <kbd>&lt;password&gt;</kbd>
Uploading, please wait...
INFO: Start uploading initrd.img
INFO: initrd.img uploaded successfully
INFO: Start uploading vmlinuz
INFO: vmlinuz uploaded successfully
</pre>
</div>

<p>These files will not appear when listing the content of the ISO domain (unless you add a &quot;<tt>.iso</tt>&quot; extension), but will be available nonetheless.</p>
<p>And here we come to the RHEV API (make sure you have installed the <tt>rhevm-sdk</tt> package); the first step, in a script, is importing the necessary modules and creating an instance of the API class, which is the base class for accessing the entire RHEV configuration:</p>

<div class="code">
<pre>
#!/usr/bin/env python

from ovirtsdk.api import API
from ovirtsdk.xml import params

URL      = &quot;https://rhevm.my.domain/api&quot;
USERNAME = &quot;admin@internal&quot;
PASSWORD = &quot;password&quot;
CA_FILE  = &quot;/etc/pki/ovirt-engine/ca.pem&quot;

api = API(url=URL, username=USERNAME, password=PASSWORD, ca_file=CA_FILE)
</pre>
</div>

<p>The certificate (<tt>CA_FILE</tt>) can be downloaded from the RHEV-manager at the URL https://<var>&lt;rhevm-server&gt;</var>/ca.crt.</p>
<p>So we're ready to create our first virtual machine; we're going to setup the VM with 2 virtual dual-core processors, 2GB of RAM and a SPICE console.</p>

<div class="code">
<pre>
VM_NAME = &quot;my_vm&quot;
CLUSTER_NAME = &quot;my_cluster&quot;
SOCKETS = 2
CORES = 2
GB = 1024**3

cpu_params = params.CPU(topology=params.CpuTopology(sockets=SOCKETS,
                                                    cores=CORES))
api.vms.add(params.VM(name=VM_NAME,
                      cluster=api.clusters.get(CLUSTER_NAME),
                      template=api.templates.get(&quot;Blank&quot;),
                      cpu=cpu_params,
                      memory=2*GB,
                      display=params.Display(type_=&quot;SPICE&quot;)))
</pre>
</div>

<p>Before proceeding to the next steps, we have to wait for the virtual machine to be in <em>down</em> state; we can use a simple function like the following:</p>

<div class="code">
<pre>
import time

def wait_state(vm_name, state):
    while api.vms.get(vm_name).status.state != state:
        time.sleep(1)

wait_state(VM_NAME, &quot;down&quot;)
</pre>
</div>

<p>Once the machine has been created and is in <em>down</em> state, we can add one or more disks and network cards; in this example, we will add a 20GB thin-provisioned disk (Copy-On-Write) and one <acronym title="Network Interface Card">NIC</acronym>:</p>

<div class="code">
<pre>
STG_DOMAIN = &quot;my_stg_domain&quot;
NIC_NAME = &quot;nic1&quot;
NET_NAME = &quot;my_network&quot;

vm = api.vms.get(VM_NAME)
stg_domain = api.storagedomains.get(STG_DOMAIN)
stg_parms = params.StorageDomains(storage_domain=[stg_domain])
<i># Boot disk</i>
vm.disks.add(params.Disk(storage_domains=stg_parms,
                         size=20*GB,
                         status=None,
                         interface='virtio',
                         format='cow',
                         sparse=False,
                         bootable=True))
<i># Boot NIC</i>
vm.nics.add(params.NIC(name=NIC_NAME,
                       network=params.Network(name=NET_NAME),
                       interface='virtio'))
boot_if = vm.nics.get(NIC_NAME).mac.address

<i># Add more disks and NICs to your liking...</i>
</pre>
</div>

<p>As you can see, I have stored the MAC address of the boot interface in the <tt>boot_if</tt> variable, in order to pass it later to the kernel to identify the boot NIC (<tt>ksdevice</tt> boot parameter); of course, this only makes sense if you have multiple NICs configured on the virtual machine.</p>
<p>Now we can set the boot parameters of the VM (kernel, init ramdisk and command line); this could have been done at the VM creation, if we didn't have to save the MAC address for the <tt>ksdevice</tt> parameter (see below for how to use the boot parameters to fully customize post-installation).</p>

<div class="code">
<pre>
boot_params = {&quot;ks&quot;: &quot;http://<satellite-server>/ks&quot;,
               &quot;ksdevice&quot;: boot_if,
               &quot;dns&quot;: &quot;1.2.3.4,1.2.3.5&quot;,
               &quot;ip&quot;: &quot;10.9.8.7&quot;,
               &quot;netmask&quot;: &quot;255.255.255.0&quot;,
               &quot;gateway&quot;: &quot;10.9.8.1&quot;,
               &quot;hostname&quot;: &quot;{0}.my.domain&quot;.format(VM_NAME)}
cmdline = &quot; &quot;.join(map(&quot;{0[0]}={0[1]}&quot;.format, d.iteritems()))
vm.set_os(params.OperatingSystem(kernel=&quot;iso://vmlinuz&quot;,
                                 initrd=&quot;iso://initrd.img&quot;,
                                 cmdline=cmdline))
vm.update()
</pre>
</div>

<p>To start the installation, we only have to power on the machine:</p>

<div class="code">
<pre>
vm.start()
</pre>
</div>

<p>Finally, to prevent the virtual machine from network-booting again after installation, we need to remove the boot parameters from its configuration. However, if the kickstart file contains the <tt>reboot</tt> directive, the machine won't re-read its configuration before rebooting and will start the installation again. Therefore, I prefer using the <tt>poweroff</tt> directive in the kickstart file and use the API to power on the machine again at the end of the installation, as soon as it will reach the <em>down</em> state.</p>

<div class="code">
<pre>
wait_state(VM_NAME, &quot;up&quot;)
<i># Remove boot parameters</i>
vm.set_os(params.OperatingSystem(kernel=&quot;&quot;, initrd=&quot;&quot;, cmdline=&quot;&quot;))
vm.update()
</i># Wait for machine to power off</i>
wait_state(VM_NAME, &quot;down&quot;)
<i># Start the VM after the installation</i>
vm.start()
api.disconnect()
</pre>
</div>

<p>Just a final note on boot parameters; one trick I like to use for customizing OS post-installation is passing arbitrary parameters to the boot line, so that the post-install script(s) can take different actions based on these parameters. For example, say you add the parameter &quot;<tt>do_stuff=y</tt>&quot; to the boot line; the kernel will just ignore it because it means nothing to it; but in the post-install section of the kickstart file, you can parse the boot line and perform different actions based on these &quot;special&quot; parameters, e.g.:</p>

<div class="code">
<pre>
%post --log /root/post-ks.log --interpreter /bin/bash
    eval $(cat /proc/cmdline)
    if [[ &quot;$do_stuff&quot; = &quot;y&quot; ]]; then
        <i># ... do stuff here ...</i>
    fi
%end
</pre>
</div>


<h3>Bibliography</h3>

<ul>
  <li><a href="http://blog.delouw.ch/2010/10/20/deploying-rhel-as-esx-guests-kickstarting-or-using-esx-templates/">Deploying RHEL as ESX guests – Kickstarting or using ESX templates?</a></li>
  <li><a href=" https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Virtualization/3.2/html/Developer_Guide/chap-Python_Quick_Start_Example.html">RHEV Developer Guide - Python Quick Start Example</a></li>
  <li><a href="https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Virtualization/3.0/html-single/REST_API_Guide/">RHEV REST API Guide</a></li>
  <li><a href="http://www.ovirt.org/Testing/PythonApi">oVirt - Testing/PythonApi</a></li>
  <li><a href="https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/5/html/Installation_Guide/s1-kickstart2-options.html">RHEL - Kickstart Options</a></li>
</ul>

  <hr />

  <div class="navigation">
    <ul>
      <li class="prev"><span class="nav-list" ><span>Previous</span></span></li>
      <li class="up"><a class="nav-list" href="../../linux.html"><span>Up</span></a></li>
      <li class="prev"><span class="nav-list" ><span>Next</span></span></li>
      <li class="home"><a class="nav-list" href="../../index.html"><span>Home</span></a></li>
    </ul>
    <h3>Automatic Virtual Machine deployment using the RHEV API and Python</h3>
    <div>Up: <a href="../../linux.html">Linux</a>
    </div>
  </div>

</body>

</html>
